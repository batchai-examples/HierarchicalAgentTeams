{
    "path": "backend/research_team.py",
    "model_usage_metrics": {
        "Duration": 16212135104,
        "OpenAiUsage": {
            "completion_tokens": 0,
            "prompt_tokens": 0,
            "total_tokens": 0,
            "completion_tokens_details": {
                "accepted_prediction_tokens": 0,
                "audio_tokens": 0,
                "reasoning_tokens": 0,
                "rejected_prediction_tokens": 0
            },
            "prompt_tokens_details": {
                "audio_tokens": 0,
                "cached_tokens": 0
            }
        }
    },
    "test_file_path": "backend/test_research_team.py",
    "existing_test_code": "",
    "original_code": "from typing import Literal\nimport asyncio\nfrom langchain_core.messages import HumanMessage, AIMessageChunk\nfrom langchain_core.runnables import RunnableConfig\nfrom langchain_openai import ChatOpenAI\nfrom langgraph.prebuilt import create_react_agent\n\nfrom langgraph.graph import StateGraph, MessagesState, START\nfrom langgraph.types import Command\n\nfrom tools import tavily_tool, scrape_webpages, make_supervisor_node\n\n#######################################################################################################################\n# Define Agent Teams\n# Now we can get to define our hierarchical teams. \"Choose your player!\"\n\n# Research Team\n# The research team will have a search agent and a web scraping \"research_agent\" as the two worker nodes. \n# Let's create those, as well as the team research_team_supervisor.\n\nllm = ChatOpenAI(model=\"gpt-4o\")\n\nsearch_agent = create_react_agent(llm, tools=[tavily_tool])\n\n\ndef search_node(state: MessagesState) -\u003e Command[Literal[\"research_team_supervisor\"]]:\n    result = search_agent.invoke(state)\n\n    last_response = result[\"messages\"][-1].content\n    return Command(\n        update={\n            \"messages\": [\n                HumanMessage(content=last_response, name=\"search\")\n            ]\n        },\n        # We want our workers to ALWAYS \"report back\" to the research_team_supervisor when done\n        goto=\"research_team_supervisor\",\n    )\n\n\nweb_scraper_agent = create_react_agent(llm, tools=[scrape_webpages])\n\n\ndef web_scraper_node(state: MessagesState, config: RunnableConfig) -\u003e Command[Literal[\"research_team_supervisor\"]]:\n    result = web_scraper_agent.invoke(state, config)\n\n    last_response = result[\"messages\"][-1].content\n    return Command(\n        update={\n            \"messages\": [\n                HumanMessage(content=last_response, name=\"web_scraper\")\n            ]\n        },\n        # We want our workers to ALWAYS \"report back\" to the research_team_supervisor when done\n        goto=\"research_team_supervisor\",\n    )\n\n\nresearch_supervisor_node = make_supervisor_node(llm, [\"search\", \"web_scraper\"])\n\n# Now that we've created the necessary components, defining their interactions is easy. \n# Add the nodes to the team graph, and define the edges, which determine the transition criteria.\n\nresearch_builder = StateGraph(MessagesState)\nresearch_builder.add_node(\"research_team_supervisor\", research_supervisor_node)\nresearch_builder.add_node(\"search\", search_node)\nresearch_builder.add_node(\"web_scraper\", web_scraper_node)\n\nresearch_builder.add_edge(START, \"research_team_supervisor\")\nresearch_graph = research_builder.compile()\n\n###############################################################################\n# from IPython.display import Image\n\n# output_path = \"research_graph.png\" \n\n# png = Image(research_graph.get_graph().draw_mermaid_png())\n# png_data = png.data\n# with open(output_path, \"wb\") as file:\n#     file.write(png_data)\n\n# print(f\"Graph has been saved to {output_path}\")\n\n###############################################################################\n# We can give this team work directly. Try it out below.\n\nasync def test_research_team():\n    async for messages in research_graph.astream(\n        {\"messages\": [(\"user\", \"when is Taylor Swift's next tour?\")]},\n        {\"recursion_limit\": 100},\n        stream_mode=\"messages\"\n    ):\n        checkpoint_ns:str = messages[1][\"checkpoint_ns\"]\n        if checkpoint_ns.startswith(\"search:\"):\n            for msg in messages:\n                if isinstance(msg, AIMessageChunk):\n                    content = msg.content\n                    if content:\n                        print(content, end=\"\", flush=True)\n\nif __name__ == \"__main__\":\n    asyncio.run(test_research_team())\n    print()\n",
    "test_code": "import unittest\nfrom unittest.mock import patch, AsyncMock\nfrom backend.research_team import search_node, web_scraper_node, test_research_team\nfrom langchain_core.messages import MessagesState\nfrom langgraph.types import Command\n\nclass TestResearchTeam(unittest.TestCase):\n\n    def setUp(self):\n        # Set up a mock MessagesState for testing\n        self.state = MessagesState(messages=[{\"role\": \"user\", \"content\": \"when is Taylor Swift's next tour?\"}])\n\n    @patch('backend.research_team.search_agent.invoke', new_callable=AsyncMock)\n    def test_search_node_happy_path(self, mock_invoke):\n        \"\"\"\n        Test the search_node function with a happy path scenario.\n        \"\"\"\n        # Mocking the response from the search agent\n        mock_invoke.return_value = {\n            \"messages\": [{\"content\": \"Taylor Swift's next tour is in 2024.\"}]\n        }\n\n        result = search_node(self.state)\n\n        # Check if the command is returned correctly\n        self.assertIsInstance(result, Command)\n        self.assertEqual(result.goto, \"research_team_supervisor\")\n        self.assertEqual(result.update[\"messages\"][0].content, \"Taylor Swift's next tour is in 2024.\")\n\n    @patch('backend.research_team.web_scraper_agent.invoke', new_callable=AsyncMock)\n    def test_web_scraper_node_happy_path(self, mock_invoke):\n        \"\"\"\n        Test the web_scraper_node function with a happy path scenario.\n        \"\"\"\n        # Mocking the response from the web scraper agent\n        mock_invoke.return_value = {\n            \"messages\": [{\"content\": \"I found information about Taylor Swift's tour.\"}]\n        }\n        \n        config = {}  # Mock config\n        result = web_scraper_node(self.state, config)\n\n        # Check if the command is returned correctly\n        self.assertIsInstance(result, Command)\n        self.assertEqual(result.goto, \"research_team_supervisor\")\n        self.assertEqual(result.update[\"messages\"][0].content, \"I found information about Taylor Swift's tour.\")\n\n    @patch('backend.research_team.search_agent.invoke', new_callable=AsyncMock)\n    def test_search_node_empty_response(self, mock_invoke):\n        \"\"\"\n        Test the search_node function when the response is empty.\n        \"\"\"\n        # Mocking an empty response from the search agent\n        mock_invoke.return_value = {\n            \"messages\": [{\"content\": \"\"}]\n        }\n\n        result = search_node(self.state)\n\n        # Check if the command is returned correctly\n        self.assertIsInstance(result, Command)\n        self.assertEqual(result.goto, \"research_team_supervisor\")\n        self.assertEqual(result.update[\"messages\"][0].content, \"\")\n\n    @patch('backend.research_team.web_scraper_agent.invoke', new_callable=AsyncMock)\n    def test_web_scraper_node_empty_response(self, mock_invoke):\n        \"\"\"\n        Test the web_scraper_node function when the response is empty.\n        \"\"\"\n        # Mocking an empty response from the web scraper agent\n        mock_invoke.return_value = {\n            \"messages\": [{\"content\": \"\"}]\n        }\n        \n        config = {}  # Mock config\n        result = web_scraper_node(self.state, config)\n\n        # Check if the command is returned correctly\n        self.assertIsInstance(result, Command)\n        self.assertEqual(result.goto, \"research_team_supervisor\")\n        self.assertEqual(result.update[\"messages\"][0].content, \"\")\n\n    @patch('backend.research_team.search_agent.invoke', new_callable=AsyncMock)\n    def test_search_node_invalid_response_structure(self, mock_invoke):\n        \"\"\"\n        Test the search_node function with an invalid response structure.\n        \"\"\"\n        # Mocking an invalid response structure from the search agent\n        mock_invoke.return_value = {\n            \"messages\": [{\"wrong_key\": \"This should fail.\"}]\n        }\n\n        with self.assertRaises(KeyError):\n            search_node(self.state)\n\n    @patch('backend.research_team.web_scraper_agent.invoke', new_callable=AsyncMock)\n    def test_web_scraper_node_invalid_response_structure(self, mock_invoke):\n        \"\"\"\n        Test the web_scraper_node function with an invalid response structure.\n        \"\"\"\n        # Mocking an invalid response structure from the web scraper agent\n        mock_invoke.return_value = {\n            \"messages\": [{\"wrong_key\": \"This should fail.\"}]\n        }\n        \n        config = {}  # Mock config\n        with self.assertRaises(KeyError):\n            web_scraper_node(self.state, config)\n\nif __name__ == '__main__':\n    unittest.main()\n",
    "amount_of_generated_test_cases": 6,
    "single_test_run_command": "python -m unittest backend/test_research_team.py"
}